\documentclass{spisok-article}
\usepackage{amssymb,amsmath,latexsym}
\usepackage{cite}
% \usepackage[T2A]{fontenc}
% \usepackage[utf8]{inputenc}
% \usepackage[english,russian]{babel}
% \usepackage{amssymb,amsmath,amsthm, mathtools}

\newtheorem{thm}{Лемма}
\newtheorem{dfn}{Определение}
\newtheorem{utv}{Утверждение}
\newtheorem{note}{Замечание}

\title{ Оценка малых вероятностей при помощи метода Монте-Карло по схеме марковской цепи}

\author{Абрамова А. Н., 
  студент кафедры статистического моделирования СПбГУ,
  abramova.asya93@gmail.com \\
  Коробейников А.И., кандидат физико-математических наук, доцент
кафедры статистического моделирования СПбГУ, a.korobeynikov@spbu.ru
}
\begin{document}

\maketitle

\begin{abstract}
  Рассматривается задача поиска пептида по базе данных и оценивания вероятности близости данного пептида к некоторому пептиду из базы. Сформулирована и формализована на вероятностном языке более простая задача сравнения данной нуклеотидной строки с некоторым множеством нуклеотидных строк. В работе предложено решение этой задачи при помощи метода Метрополиса-Гастингса и алгоритма Ванга-Ландау.

\end{abstract}

\section{Введение}
  Пептиды --- это семейство веществ, молекулы которых построены из двух и более остатков аминокислот, соединённых в цепь пептидными  связями. Существуют бактерии способные продуцировать пептидные соединения, подавляющие рост определённых микроорганизмов или вызывающие их гибель, то есть антибиотики.

  Важным вопросом, связанным с исследованием пептидов, является их идентификация. Другими словами, необходимо понять, насколько исследуемый пептид $P$ близок по структуре к некоторому известному пептиду $P^*$ (близость структур пептидов влечет за собой близость их свойств). Наиболее распространенным инструментом для решения данной задачи является масс-спектрометрия. Методы масс-спектрометрии заключаются в том, что по данному пептиду экспериментально строится его так называемая <<\textit{фрагментация}>>, после чего измеряется масса каждого фрагмента, и в дальнейшем исследуется полученный массив масс, именуемый \textit{спектром} \cite{spectrum}.

  Таким образом, существует задача идентификации пептида по его масс-спектру: исследование схожести двух пептидов сводится к исследованию схожести их спектров, а именно к оценке их близости на статистическом языке.


  Существуют определенные методы, в том или ином роде решающие данную задачу (например, \cite{msdpr}).
  Тем не менее, остается неизвестной точность полученных оценок, а также возникает потребность увеличения скорости работы существующих алгоритмов в связи с большими объемами данных, которые характерны для поставленной задачи.

  На начальном этапе была рассмотрена упрощенная задача --- задача идентификации нуклеотидных строк, которую формально опишем в следующем разделе.


\section{Постановка задачи}
Обозначим $\sigma = \{A, C, G, T\}$, зафиксируем $k \in \mathbb{N}$.
Пусть $\sigma_k$ --- множество всех строк длины $k$ над алфавитом $\sigma$.
\begin{dfn}
\label{dfn:aln}
Рассмотрим строки $x, y \in \sigma_k$. Локальным выравниванием длины $m$ строк $x$ и $y$ будем называть набор индексов $B = B(x, y) = \{(i_1, j_1), \ldots, (i_m, j_m)\}$, где: 
\begin{enumerate}
\item При $u < v$ выполняется $i_u < i_v$, $j_u < j_v$, 
\item Для любыx $u, v$: если $i_u  < j_u$, то $i_v < j_v$.
\end{enumerate}
Дополнительно, если для любого $u \in \{1, \ldots, m \}$  выполняется $i_{u+1} = i_u + 1$ и $j_{u + 1} = j_u + 1$,
то выравнивание называется выравниванием без пропусков.
\end{dfn}
Множество всевозможных выравниваний будем обозначать $\mathbb{B}$. На множестве пар строк определим функцию <<расстояния>> $s$, такую что для строк $x, y \in \sigma_k$:
\begin{gather*}
s(x, y)\!=\!\max\limits_{B, m}\!\left(\!c\!\sum\limits_{\ell = 1}^{m} \mathbb{I}_{\{x_{i_\ell} = y_{j_\ell}\!\} }\!+\!d\!\sum\limits_{\ell = 1}^{m} \mathbb{I}_{\{x_{i_\ell} \ne y_{j_\ell}\!\}}\!+\!h\!\sum\limits_{\ell = 1}^{m - 1}\!\max \{ i_{\ell \!+\!1}\!-\!i_\ell, j_{\ell \!+ \!1}\!-\!j_\ell\}\!\right)\!,
\end{gather*}
где $c, d, h \in \mathbb{R}$ --- некоторые фиксированные константы.


\begin{note}
Значения функции $s$ зависят от параметров $c, d$ и $h$, поэтому само значение $s(x, y)$ для некоторых $x, y \in \sigma_k$ не несет никакой информации относительно их <<близости>>.
Поэтому можно рассматривать следующие задачи:
\begin{enumerate}
\item Вычислить $\# \{(x, y):s(x, y) > S^* \}$, где $S^*$ --- заранее заданный порог.  
\item Вычислить $\# \{y:s(x_0, y) > S^* \}$, где $S^*$ --- заранее заданный порог, $x_0 \in \sigma_k$ --- фиксированная строка.
\end{enumerate}
Вторая задача соответствует поиску образца в базе, где базой является множество $\sigma_k$, и поэтому далее мы будем рассматривать ее.
\label{note:probl}
\end{note}

\section{Статистическая постановка задачи}
Теперь формализуем задачу с вероятностной точки зрения. Для этого будем считать, что строки --- случайные величины.

Пусть $\mathbf{2}^{\sigma_k}$~--- множество всех подмножеств $\sigma_k$.
$\mathcal{P}_k$~--- распределение на $\sigma_k$, такое что $\mathcal{P}_k(A) = \#A/\#\sigma_k$ для любого $A \in \mathbf{2}^{\sigma_k}$.
На некотором вероятностном пространстве $(\Omega, \mathcal{F}, \mathbb{P})$ определим случайную величину $\xi:(\Omega, \mathcal{F}) \longrightarrow (\sigma_k, \mathbf{2}^{\sigma_k})$, такую что $\mathbb{P}(\xi \in A) = \mathcal{P}_k(A)$ для любого $A \in \mathbf{2}^{\sigma_k}$. Таким образом, все буквы строки будут равновероятны.

Зафиксируем строку $x_0 \in \sigma_k$. Тогда в статистическом смысле задача, описанная в замечании \ref{note:probl}, эквивалентна оценке вероятности 
\begin{equation}
p = \mathbb{P}(s(x_0, \xi) > S^*).
\label{eqn:main_prob}
\end{equation}

Известно, что для локального выравнивания без пропусков имеется следующий асимптотический результат \cite{BLAST}: распределение значений функции $s$ сходится к распределению Гумбеля с определенными параметрами при $k  \to \infty$. В дальнейшем для сравнения оценок величины \eqref{eqn:main_prob}, полученных в результате реализованного алгоритма, мы будем использовать оценки, полученные при помощи программы BLAST, которая использует данную асимптотическую аппроксимацию (подробнее см.\cite{BLAST}).  

\begin{note}
\label{note:score}
Далее будем обозначать $s(y) := s(x_0, y)$.
\end{note}

\section{Проблема оценки редких событий} 
Стандартным методом оценивания вероятности \eqref{eqn:main_prob} является метод Монте-Карло.
Рассмотрим случайную величину $\xi$, определенную на некотором вероятностном пространстве $(\Omega, \mathcal{F}, \mathbb{P})$ с распределением $\mathcal{P}$. Обозначим $p = \mathbb{P}(\xi \in A)$, $A$ --- некоторое борелевского множество. 

\begin{dfn}
Пусть $x_1, \ldots, x_N$ --- независимые одинаково распределенные случайные величины с распределением $\mathcal{P}$. Оценкой по методу Монте-Карло называется
\begin{equation*}
\widehat{p}_{MC} =
\frac{1}{N} \sum\limits_{i = 1}^N \mathbb{I}_{\{x_i \in A\}}.
\end{equation*}
\end{dfn}

Заметим, что дисперсия такой оценки $\mathbb{D}(\widehat{p}_{MC}) = \frac{p(1 - p)}{N}$. 
В задаче оцениваемая вероятность $p$ крайне мала, поэтому оценки, полученные при помощи метода Монте-Карло, будут обладать очень большой дисперсией по отношению к $p_{MC}$. Вследствие этого задача получения оценок с заданной точностью становится очень трудоемкой, поэтому будем использовать метод МСМС (Markov Chain Monte-Carlo).

\subsection{Оценка по методу MCMC}
\paragraph{Метод существенной выборки}
В предложенных выше обозначениях рассмотрим следующий способ построения оценки $\widehat{p}$. Пусть $\mathcal{Q}$ --- некоторое распределение, определенное на $(\Omega, \mathcal{F})$ с соответствующей функцией распределения $Q$ и плотностью $q$ относительно некоторой меры $\nu$.
 Предположим также, что существует производная Радона-Никодима $d\mathcal{P} / d\mathcal{Q}$ (в данном случае  $ (d\mathcal{P} / d\mathcal{Q})(x) = f(x)/q(x)$ в точках, где $q(x) \ne 0$ и равна нулю в точках, где $q(x) = 0$). 

\begin{dfn}
Пусть $x_1, \ldots, x_N$ ---  одинаково распределенные случайные величины с распределением $\mathcal{Q}$.
Оценкой Монте-Карло по методу существенной выборки для вероятности $p$ будем называть
\begin{gather*}
\widehat{p} = \frac{1}{N}\sum\limits_{i = 1}^N \frac{f(x_i)}{q(x_i)} \mathbb{I}_{\{x_i \in A\}}.
\end{gather*}
Такая оценка будет несмещенной оценкой $p$.
\end{dfn} 


\paragraph{Выбор моделирующего распределения $\mathcal{Q}$}
Далее, будем считать, что плотность $q$ имеет конкретный вид, а именно
\begin{equation}
\label{eqn:dens_q}
q(x) = c w(s(x))f(x),
\end{equation} где $w$ --- некоторая положительная функция, $c > 0$ --- нормирующая константа, $s$ --- функция, определенная в замечании \eqref{note:score}.
\begin{utv}
Если плотность $q$  имеет вид \eqref{eqn:dens_q}, то оценка
\begin{gather}
\label{eqn:main_est}
\widehat{p} = \frac{\sum\limits_{n = 1}^{N} \mathbb{I}_{\{X_n \in A\}}/w(s(X_n))} {\sum\limits_{n = 1}^{N} 1/w(s(X_n))}, 
\end{gather}
является несмещенной оценкой $p$.
\end{utv}


\paragraph{Выбор весовой функции $w$}
Напомним, что нашей задачей является оценка вероятности \eqref{eqn:main_est} и необходимо минимизировать относительную ошибку ($\mathbb{D}\widehat{p}_{MC}/p_{MC}$) этой оценки, поэтому будем искать функцию $q$ вида \eqref{eqn:dens_q} так, чтобы для случайной величины $\xi \sim \mathcal{Q}$ распределение $s(\xi)$ было близко к равномерному распределению на $[S_{min}, S_{max}]$. Для этого достаточно выбирать весовую функцию $w$ так, чтобы $w(S) \approx 1/\mathbb{P}(s(\xi) = S)$.

%Так как событие $\{s(\xi) > S^* )\}$ является редким, то желательно, чтобы моделирующая плотность $q$ была сосредоточена на тех $x$, что $s(x) \in [S^*, S_{max} ]$, где $S_{max}$ --- максимальное значение функции $s$.

\paragraph{Построение марковской цепи}

Будем моделировать марковскую цепь $(X_n)_{n \ge 1}$ со стационарным распределением $\mathcal{Q}$ с помощью метода Метрополиса-Гастингса \cite{MH}. Для этого достаточно задать переходную плотность марковской цепи, удовлетворяющей уравнению детального баланса \cite{MHbalance}.

Теперь опишем, как выглядит переходная плотность $\gamma$ в поставленной задаче. 
Пусть $x$ --- текущее состояние. Тогда новое состояние $y$ получим следующим образом:
смоделируем случайную величину $j$ равномерно на множестве индексов ${\{1, \ldots, k \}}$ и букву $ch$ равномерно на множестве $\sigma = {\{A, C, G, T\}}$.
\begin{itemize}
\item С вероятностью 1/2 положим $y[z] \leftarrow x[z]$ для $z = 1, \ldots, k$, $y[j] \leftarrow ch$, 
\item С вероятностью 1/8 положим $y[z] \leftarrow x[z + 1]$ для $z = j, \ldots, k - 1$, $y[k] \leftarrow ch$
\item С вероятностью 1/8 положим $y[z] \leftarrow x[z - 1]$ для $z = 2, \ldots, j$, $y[1] \leftarrow ch$
\item С вероятностью 1/8 положим $y[z + 1] \leftarrow x[z]$, $z = j, \ldots k - 1$, $y[j] \leftarrow ch$.
\item С вероятностью 1/8 положим $y[z - 1] \leftarrow x[z]$, $z = 2, \ldots j $, \\ $y[j] \leftarrow ch$.
\end{itemize}

\begin{note}
Для данной переходной плотности и целевой плотности $q$, вероятность перехода в новое состояние равна $\min \left(\frac{w(s(x))}{w(s(y))} , 1\right)$.
\end{note}

Весовую функцию $w$ будем оценивать алгоритмом Ванга-Ландау, который в общем виде описан в \cite{wl}. 
Данный алгоритм является адаптивной модификацией метода Метрополиса-Гастингса и позволяет оценить требуемые веса одновременно с моделированием траектории марковской цепи.

Однако получающаяся в результате работы алгоритма марковская цепь нестационарна и, вообще говоря, не обязательно
является эргодической. В связи с этим, построение оценок проводится в два этапа: сначала при помощи алгоритма Ванга-Ландау оцениваются значения функции $w(s)$, затем полученные веса используются для моделирования марковской цепи  с соответствующей целевой плотностью $q$ методом Метрополиса-Гастингса. 


\section{Численные результаты}
Результатом описанного алгоритма является марковская цепь  $\tilde{X}_1,\ldots, \tilde{X}_{M_{max}}$ со стационарным распределением $\mathcal{Q}$.

Чтобы строить доверительные интервалы для оценки \eqref{eqn:main_est} необходимо знать ее дисперсию, а значит нужно получить набор слабо коррелированных  величин $X_1, \ldots X_N$.
При помощи пакета <<coda>> языка программирования \textbf{R} \cite{coda} изменим полученную марковскую цепь следующим образом:
\begin{enumerate}
\item Найдем такой индекс $k$ в траектории, начиная с которого наступает момент <<стабилизации>>, и рассмотрим $\tilde{X}_{k}, \ldots, \tilde{X}_{M_{max}}$ (функция cumuplot).
\item С помощью функции autocorr.diag найдем такое значение $l$, что корреляция между $X_{k}$ и $\tilde{X}_{k + l}$ достаточно мала и положим
\begin{gather*}
X_i = \tilde{X}_{k + l(i - 1)}, \text{для } i = 1,\ldots, \left[\frac{M_{max} - k}{l}\right].
\end{gather*} 
\end{enumerate}

Полученные оценки будем сравнивать следующим образом:
\begin{enumerate}
\item Для строк длины $k$ при $S^* = S_{max}$ в \eqref{eqn:main_prob} оцениваемая вероятность равна $1/ |\sigma|^k$.
\item Сравним результаты описанного алгоритма с методом Монте-Карло.
\item Проведем сравнение с BLAST (с оценками на основе асимптотических результатов).
\end{enumerate}
Результаты описанных выше сравнений представлены в таблице \ref{tbl:comp10}. 
\begin{table}[h]
\centering

\caption{Сравнение методов, $k = 10$, теоретическое значение $p-value$ для $S^* = 10$ равняется $9.5 \cdot 10^{-7}$} 
\label{tbl:comp10}
\begin{tabular}{|c|c|c|}
\hline
            & $S^* = 10$  & $S^* = 8$   \\ \hline
            & $\widehat{p}$        & $\widehat{p}$       \\ \hline
MC          &  $5 \cdot 10^{-7}$       &   0.00014            \\ \hline
MCMC        &  $1.3 \cdot 10^{-6}$  &   0.00013                        \\ \hline
BLAST        & $5 \cdot 10^{-5}$      & $8 \cdot 10^{-4}$                   \\ \hline
\end{tabular}
\end{table}
Вычисление доверительных интервалов для оценок по полученному методу является нетривиальной задачей, которая будет рассмотрена при дальнейшей работе.


\section{Заключение}
 В работе был рассмотрен вопрос сравнения двух случайных строк заданной длины над фиксированным алфавитом.Также был реализован алгоритм, вычисляющий оценки для вероятности \eqref{eqn:main_prob} при помощи метода Метрополиса-Гастингса и Ванга-Ландау.
Было проведено сравнение данного метода со стандартным методом Монте-Карло и численно была продемонстрирована адекватность полученных оценок.
В дальнейшем планируется модифицировать данный алгоритм для сравнения близости пептидных спектров и сравнить его с уже существующими методами.

\renewcommand\refname{Литература}
\begin{thebibliography}{8}
\bibitem{BLAST} Altschul S. F., Gish W., W. M. Basic local alignment search tool // Journal of Molecular
Biology. --- 1990. --- Vol. 215. --- P. 403–410.

\bibitem{MH} David D. L. M., Minh D. L. P. Understanding the Hastings algorithm // Communications
in Statistics - Simulation and Computation. --- 2014. --- Vol. 44. --- P. 332–349.

\bibitem{MHbalance} Harris T. E. The existence of stationary measures for certain Markov processes. // In
Proc. 3rd Berkeley Symp. Math. Statist. Probab. --- Vol. 2. --- California Press, Berkeley,
1956. --- P. 113 -- 124.

\bibitem{wl} Iba Y., Saito N. D., Kitajima A. Multicanonical MCMC for sampling rare events: An illustrative
review. // Annals of the Institute of Statistical Mathematics. --- 2014. --- Vol. 66. ---
P. 611–645.

\bibitem{coda} Plummer M., Best N., Cowles K. et al. coda: Output analysis and diagnostics for
MCMC. --- 2015. 
%\href{https://cran.r-project.org/web/packages/coda/index }
\bibitem{msdpr} Mohimani H., Kim S., Pevzner P. A. A New Approach to Evaluating Statistical Significance of Spectral
Identifications // Journal of Proteome Research. --- Department of Electrical and Computer Engineering and Department of Computer Science and Engineering, University of
California --- San Diego, San Diego, California 92093 

\bibitem{spectrum} Mohimani H., Liu, W., Mylne, J., Poth, A., Colgrave M., Tran D., Selsted M., Dorrestein P., Pevzner P. Cycloquest: Identification of cyclopeptides via database search of their mass spectra against
genome databases // Journal of Proteome Research. --- 2011 --- Vol. 10 --- P. 4505−4512.

\end{thebibliography}

\end{document}
